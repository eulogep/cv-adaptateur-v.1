# MatchCV ğŸ¯

> J'en avais marre de rÃ©Ã©crire mon CV Ã  la main pour chaque offre. Alors j'ai codÃ© un truc pour le faire Ã  ma place.

**â†’ [Voir l'app](https://cv-adaptateur-v-1.vercel.app)** Â· **[Voir l'API](https://cv-adaptateur-v1-production.up.railway.app/docs)**

---

## C'est quoi ?

Une app web qui prend ton CV + une offre d'emploi, et qui te sort :
- Un CV **rÃ©Ã©crit et rÃ©organisÃ©** pour cette offre prÃ©cise
- Une **lettre de motivation** personnalisÃ©e
- Un **score ATS** pour savoir si tu passeras les filtres RH
- Les **mots-clÃ©s manquants** que les RH recherchent
- Un **export PDF** propre, prÃªt Ã  envoyer

Tout Ã§a gratuitement, sans crÃ©er de compte, sans payer d'API.

---

## Pourquoi j'ai fait Ã§a

En cherchant mon alternance, j'ai postulÃ© Ã  des dizaines d'offres. Ã€ chaque fois, mÃªme galÃ¨re : reformuler les mÃªmes compÃ©tences diffÃ©remment, mettre certaines choses en avant selon le poste, rÃ©Ã©crire la lettre de motivation...

J'ai commencÃ© Ã  utiliser des LLMs pour m'aider, puis j'ai rÃ©alisÃ© que je pouvais automatiser tout le process. Donc voilÃ  â€” j'ai construit MatchCV pendant ma recherche d'alternance, pour ma propre recherche d'alternance. C'est rÃ©cursif et j'aime Ã§a.

---

## Comment Ã§a marche

```
Ton CV (PDF ou texte)
        +
Texte de l'offre
        â†“
Score ATS calculÃ© localement (0 API = 0 coÃ»t)
        â†“
LLM qui rÃ©Ã©crit ton CV et gÃ©nÃ¨re la lettre
(Groq â†’ Mistral â†’ Ollama selon dispo)
        â†“
Export PDF prÃªt Ã  envoyer
```

---

## Stack (tout gratuit)

**Frontend** â€” React + Vite, CSS vanilla, dÃ©ployÃ© sur Vercel

**Backend** â€” FastAPI Python, dÃ©ployÃ© sur Railway (500h gratuites/mois)

**IA** â€” Groq (Llama 3.3 70B) comme LLM principal, Mistral en backup, Ollama en local pour le dev. Si l'un tombe, le suivant prend le relais automatiquement.

**Score ATS** â€” 100% local, basÃ© sur les keywords, zÃ©ro appel API

---

## Lancer le projet en local

Tu auras besoin de Python 3.10+, Node.js 18+ et une clÃ© API Groq gratuite (â†’ [console.groq.com](https://console.groq.com))

```bash
# Cloner
git clone https://github.com/eulogep/cv-adaptateur-v.1.git
cd cv-adaptateur-v.1

# Backend
cd backend
cp .env.example .env
# â†’ coller ta GROQ_API_KEY dans le .env
pip install -r requirements.txt
python3 -m uvicorn main:app --reload --port 8000

# Frontend (dans un autre terminal)
cd frontend
npm install
echo "VITE_API_URL=http://localhost:8000" > .env
npm run dev
```

L'app tourne sur `http://localhost:5173` et la doc API sur `http://localhost:8000/docs`.

---

## Variables d'environnement

**Backend (`backend/.env`)**

| Variable | Quoi | Obligatoire |
|---|---|---|
| `GROQ_API_KEY` | Ta clÃ© Groq â†’ [console.groq.com](https://console.groq.com) | âœ… |
| `MISTRAL_API_KEY` | Backup LLM â†’ [console.mistral.ai](https://console.mistral.ai) | âŒ |
| `OLLAMA_BASE_URL` | Si tu veux tourner en local (dÃ©faut: `http://localhost:11434`) | âŒ |

**Frontend (`frontend/.env`)**

| Variable | Quoi |
|---|---|
| `VITE_API_URL` | URL du backend (ex: `http://localhost:8000`) |

---

## API â€” les 3 endpoints

**`POST /api/parse-pdf`** â€” Extrait le texte d'un PDF
```json
// Body: multipart/form-data, champ "file" (PDF max 10MB)
// RÃ©ponse:
{ "text": "...", "chars": 1842 }
```

**`POST /api/score`** â€” Score ATS CV vs offre
```json
// Body:
{ "cv_text": "...", "offer_text": "..." }
// RÃ©ponse:
{ "score": 78, "level": "Bon", "advice": "..." }
```

**`POST /api/adapt`** â€” Le cÅ“ur â€” adaptation par LLM
```json
// Body:
{ "cv_text": "...", "offer_text": "..." }
// RÃ©ponse:
{
  "titre": "Data Scientist IA",
  "resume": "...",
  "competences": { "techniques": [...], "soft_skills": [...] },
  "experiences": [...],
  "lettre_motivation": "...",
  "mots_cles_ajoutes": [...],
  "_provider": "Groq (llama-3.3-70b)"
}
```

---

## Structure du projet

```
cv-adaptateur-v.1/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py          # Routes FastAPI
â”‚   â”œâ”€â”€ llm.py           # Fallback chain Groq â†’ Mistral â†’ Ollama
â”‚   â”œâ”€â”€ ats_score.py     # Score ATS sans API
â”‚   â”œâ”€â”€ pdf_parser.py    # Extraction texte PDF
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ CVInput.jsx    # Upload PDF / textarea
â”‚           â”œâ”€â”€ ATSGauge.jsx   # Jauge SVG animÃ©e
â”‚           â”œâ”€â”€ CVResult.jsx   # RÃ©sultat avec onglets
â”‚           â”œâ”€â”€ PDFExport.jsx  # Export @react-pdf
â”‚           â””â”€â”€ Loader.jsx
â”‚
â””â”€â”€ README.md
```

---

## Ce que j'ai appris en le faisant

- GÃ©rer un fallback entre plusieurs providers LLM proprement
- DÃ©ployer une API FastAPI sur Railway avec nixpacks
- Parser des PDFs en Python sans perdre le formatage
- GÃ©nÃ©rer des PDFs cÃ´tÃ© client avec `@react-pdf/renderer`
- Que le plus dur dans un side project c'est pas le code â€” c'est de finir

---

## Ce qui viendra aprÃ¨s (si j'ai le temps)

- [ ] Upload PDF sans copier-coller
- [ ] Historique des candidatures
- [ ] Scraping URL d'offre directement
- [ ] 2-3 templates de CV diffÃ©rents
- [ ] Mode mobile propre

---

## Providers LLM utilisÃ©s

| Provider | ModÃ¨le | Limite gratuite |
|---|---|---|
| Groq | llama-3.3-70b-versatile | 14 400 req/jour |
| Mistral AI | mistral-small-latest | 1 milliard tokens/mois |
| Ollama | mistral:7b-instruct | IllimitÃ©e (local) |

---

Fait par **Euloge Junior MABIALA** â€” Ã©tudiant en 3Ã¨me annÃ©e Ã  l'ESIEA Paris, en recherche d'alternance Data Science & IA pour septembre 2026.

[GitHub](https://github.com/eulogep) Â· [Portfolio](https://eulogep.github.io/portefolio_new/)
